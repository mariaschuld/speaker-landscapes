{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract information for the speaker landscape\n",
    "\n",
    "Running this notebook will read in the `word_embedding.emb` and `clean_data.txt` files to extract information that is important to visualise and analyse the speaker landscape.\n",
    "\n",
    "The information is stored in a pandas dataframe and the file `landscape_info.pkl` and can be read into a dataframe using `output = pd.read_pickle(\"landscape_info.pkl\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a dataframe with authors, their tweets and vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_seed = 42\n",
    "retain_threshold = 0 # NOTE: The original paper used retain_threshold=15, but for this small example such a value will remove all data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = KeyedVectors.load(\"word_embedding.emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents in training set:  442\n",
      "Number of agents with more than 0 tweets:  442\n"
     ]
    }
   ],
   "source": [
    "# Turn data text file into pandas dataframe\n",
    "\n",
    "quotes = []\n",
    "agents = []\n",
    "\n",
    "with open(\"clean_data.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split(\" \")\n",
    "        if l and l[1:]:\n",
    "            agents.append(l[0])\n",
    "            quotes.append([\" \".join(l[1:])])\n",
    "\n",
    "df = pd.DataFrame({\"author\": agents, \"quotes\": quotes})\n",
    "\n",
    "# summarise same agents\n",
    "df = df.groupby([\"author\"], as_index=False).agg({'quotes': 'sum'})\n",
    "print(\"Number of agents in training set: \", len(df.index))\n",
    "\n",
    "# only take agents with more than so many tweets\n",
    "df = df[df.quotes.map(len) > retain_threshold]\n",
    "print(\"Number of agents with more than \" + str(retain_threshold) + \" tweets: \", len(df.index))\n",
    "\n",
    "# store the vector representation of the agent\n",
    "df[\"vec\"] = df.apply(lambda row: embedding[row.author], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quotes</th>\n",
       "      <th>vec</th>\n",
       "      <th>low_dim_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent_0sternchen</td>\n",
       "      <td>[@mountaindream5 @spaet68er @zuma_monty nur fü...</td>\n",
       "      <td>[-0.0072948337, 0.08525834, 0.088255815, 0.030...</td>\n",
       "      <td>[9.962139, 6.6214237]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent_1st_rins</td>\n",
       "      <td>[@zuma_okemaru @1st_rins 1st_rins, @zuma_okema...</td>\n",
       "      <td>[-0.07338741, 0.038354628, 0.07268287, 0.04553...</td>\n",
       "      <td>[10.167288, 7.139133]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_80pfarelo</td>\n",
       "      <td>[@frasimphi @coruscakhaya you will follow this...</td>\n",
       "      <td>[-0.030285044, -0.027092239, 0.012962351, 0.04...</td>\n",
       "      <td>[3.380585, 7.387287]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agent___xmo4</td>\n",
       "      <td>[@zuma_okemaru ご飯食べたらあそぼ！, @zuma_okemaru ご飯食べた...</td>\n",
       "      <td>[-0.044664677, 0.028426673, 0.043664575, 0.035...</td>\n",
       "      <td>[9.915042, 6.950782]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agent__africansoil</td>\n",
       "      <td>[💻pres zuma discussion with the top 6 presiden...</td>\n",
       "      <td>[-0.097087175, 0.06697575, -0.17402579, -0.052...</td>\n",
       "      <td>[5.191036, 6.15981]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>agent_zenande_monegi</td>\n",
       "      <td>[@mugabebobby @flawmade @100kmokone @mightijam...</td>\n",
       "      <td>[-0.022949548, -0.10549712, 0.0016295762, 0.18...</td>\n",
       "      <td>[3.0828862, 5.9407344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>agent_zukile_lize</td>\n",
       "      <td>[@advobarryroux zuma is the worst to tell us t...</td>\n",
       "      <td>[0.06030377, -0.13764329, -0.09635882, 0.13789...</td>\n",
       "      <td>[3.6614578, 5.330434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>agent_zuma0240</td>\n",
       "      <td>[参加型第5人格！！サバイバー達我が勝利への糧となれ！ランク戦まで！ #identityv ...</td>\n",
       "      <td>[-0.10415595, 0.056165773, 0.17486429, 0.07228...</td>\n",
       "      <td>[10.337763, 7.356607]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>agent_zuma_0807</td>\n",
       "      <td>[2021年2月27日 zuma_0807さんがnew眠しました。 時刻 615 入眠潜時 ...</td>\n",
       "      <td>[-0.07631513, 0.059613544, 0.12885502, 0.09154...</td>\n",
       "      <td>[10.303881, 7.2586274]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>agent_zuma_okemaru</td>\n",
       "      <td>[@pyon09290929 荒野名￤carrierzzma 代表者id￤@zuma_oke...</td>\n",
       "      <td>[-0.057824485, 0.032707047, 0.08238833, 0.0337...</td>\n",
       "      <td>[10.274162, 7.2672315]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                             quotes  \\\n",
       "0        agent_0sternchen  [@mountaindream5 @spaet68er @zuma_monty nur fü...   \n",
       "1          agent_1st_rins  [@zuma_okemaru @1st_rins 1st_rins, @zuma_okema...   \n",
       "2         agent_80pfarelo  [@frasimphi @coruscakhaya you will follow this...   \n",
       "3            agent___xmo4  [@zuma_okemaru ご飯食べたらあそぼ！, @zuma_okemaru ご飯食べた...   \n",
       "4      agent__africansoil  [💻pres zuma discussion with the top 6 presiden...   \n",
       "..                    ...                                                ...   \n",
       "437  agent_zenande_monegi  [@mugabebobby @flawmade @100kmokone @mightijam...   \n",
       "438     agent_zukile_lize  [@advobarryroux zuma is the worst to tell us t...   \n",
       "439        agent_zuma0240  [参加型第5人格！！サバイバー達我が勝利への糧となれ！ランク戦まで！ #identityv ...   \n",
       "440       agent_zuma_0807  [2021年2月27日 zuma_0807さんがnew眠しました。 時刻 615 入眠潜時 ...   \n",
       "441    agent_zuma_okemaru  [@pyon09290929 荒野名￤carrierzzma 代表者id￤@zuma_oke...   \n",
       "\n",
       "                                                   vec             low_dim_vec  \n",
       "0    [-0.0072948337, 0.08525834, 0.088255815, 0.030...   [9.962139, 6.6214237]  \n",
       "1    [-0.07338741, 0.038354628, 0.07268287, 0.04553...   [10.167288, 7.139133]  \n",
       "2    [-0.030285044, -0.027092239, 0.012962351, 0.04...    [3.380585, 7.387287]  \n",
       "3    [-0.044664677, 0.028426673, 0.043664575, 0.035...    [9.915042, 6.950782]  \n",
       "4    [-0.097087175, 0.06697575, -0.17402579, -0.052...     [5.191036, 6.15981]  \n",
       "..                                                 ...                     ...  \n",
       "437  [-0.022949548, -0.10549712, 0.0016295762, 0.18...  [3.0828862, 5.9407344]  \n",
       "438  [0.06030377, -0.13764329, -0.09635882, 0.13789...   [3.6614578, 5.330434]  \n",
       "439  [-0.10415595, 0.056165773, 0.17486429, 0.07228...   [10.337763, 7.356607]  \n",
       "440  [-0.07631513, 0.059613544, 0.12885502, 0.09154...  [10.303881, 7.2586274]  \n",
       "441  [-0.057824485, 0.032707047, 0.08238833, 0.0337...  [10.274162, 7.2672315]  \n",
       "\n",
       "[442 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce vectors to 2-d representation using UMAP and add to the dataframe\n",
    "\n",
    "vecs = df[\"vec\"].tolist() \n",
    "reducer = umap.UMAP(metric=\"cosine\", min_dist=0.01, n_neighbors=40, random_state=umap_seed)\n",
    "smaller_vecs = reducer.fit_transform(vecs)\n",
    "\n",
    "df[\"low_dim_vec\"] = list(smaller_vecs)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"landscape_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a dataframe with annotating words and their vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hashtags as an example of annotating words\n",
    "\n",
    "vocab = embedding.index_to_key\n",
    "hashtags = [word for word in vocab if \"#\" in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute large and small vector representation\n",
    "hashtags_vecs = [embedding[h] for h in hashtags]\n",
    "hashtags_low_dim_vecs = list(reducer.transform(np.array(hashtags_vecs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.DataFrame({\"word\": hashtags, \"vec\": hashtags_vecs, \"low_dim_vec\": hashtags_low_dim_vecs})\n",
    "df_annotations.to_pickle(\"annotations_info.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landscape_env",
   "language": "python",
   "name": "landscape_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
